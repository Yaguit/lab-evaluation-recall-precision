{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "\n",
    "Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics.\n",
    "\n",
    "We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now take a look at the shapes of the X and y matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's pick one entry and see what number is written. Use indexing to pick the 35th digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  29., 141., 198., 255., 198.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  86., 141., 198., 255., 255., 255., 255.,\n",
       "       170.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  29., 141., 226., 255.,\n",
       "       255., 255., 255., 198.,  86.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 170., 255., 255., 170.,  86.,  86.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 141., 226., 170.,  57.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  86., 255., 198.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 198., 255., 141.,  86.,\n",
       "        57.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 170., 255., 198., 114., 226., 170.,  29.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  57., 198., 255., 114.,  29.,   0.,\n",
       "       141., 255.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       114., 255., 114.,   0.,   0.,   0., 141., 255.,  29.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  29.,   0.,   0.,   0.,\n",
       "         0., 226., 255.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 114., 255., 141.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  86.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       114., 226., 226.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255., 198.,\n",
       "        86.,   0.,   0.,   0., 141., 255., 255., 170.,  29.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 226., 255., 226., 170., 226., 255., 255.,\n",
       "       198.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  86.,\n",
       "       198., 255., 255., 170., 141.,  57.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "a = X[35]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Use the *reshape(28,28)* method and *plt.imshow()* function with the parameters *cmap = matplotlib.cm.binary* and *interpolation=\"nearest\"* to make a plot of the number. Be sure to import matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a7b06d05c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_digit_image= a.reshape(28,28)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(X_digit_image, cmap=matplotlib.cm.binary, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use indexing to see if what the plot shows matches with the outcome of the 35th index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "y[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training and the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5 = np.where(y == \"5\", 1, 0)\n",
    "y5_train, y5_test = y5[:60000], y5[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_5 = y5[:60000]\n",
    "y_test_5 = y5[60000:]\n",
    "y5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train a logistic regression to predict if a number is a 5 or not. Remember to use the 'just 5s' target train array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yago\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the classifier predict correctly the 35th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "y5_pred = model.predict(X)\n",
    "print(y5_pred[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your comments here\n",
    "#yes, the prediction is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 36000th value is a 9. Check if it was correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(y5_pred[36000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your comments here\n",
    "#yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumb classifier\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1))[:, 0]\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets fit and predict on the testing set using our dumb classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "y_never5_pred = never_5_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9108    0]\n",
      " [ 892    0]]\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "confusion_never5 = confusion_matrix(y_test_5, y_never5_pred) \n",
    "f1_never5 = f1_score(y_test_5, y_never5_pred)\n",
    "precision_never5 = precision_score(y_test_5, y_never5_pred)\n",
    "recall_never5 = recall_score(y_test_5, y_never5_pred)\n",
    "\n",
    "print(confusion_never5)\n",
    "print(f1_never5)\n",
    "print(precision_never5)\n",
    "print(recall_never5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([0., 1.]), array([1., 0.]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_curve(y_test_5, y_never5_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_5, y_never5_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
